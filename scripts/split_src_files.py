#!/usr/bin/env python3
"""
å°† project_files.md ä¸­ src/ ç›®å½•ä¸‹çš„æ–‡ä»¶æŒ‰æ¯ 5 ä»½ä¸€ç»„åˆ†å‰²ï¼Œ
ç”Ÿæˆç”¨äºåˆ†æ KarisCode é‡å†™å®Œæ•´æ€§çš„è¯·æ±‚å¥å­ã€‚
"""

import re
from pathlib import Path


def parse_project_files(content: str) -> dict[str, list[str]]:
    """è§£æ project_files.mdï¼Œæå– src/ ç›®å½•ä¸‹çš„æ–‡ä»¶åˆ—è¡¨ã€‚"""
    directories = {}
    current_dir = None

    lines = content.split('\n')
    for line in lines:
        # åŒ¹é…ç›®å½•æ ‡é¢˜ï¼š## ğŸ“ src/xxx
        dir_match = re.match(r'^## ğŸ“ (src/.*)$', line)
        if dir_match:
            current_dir = dir_match.group(1)
            directories[current_dir] = []
            continue

        # åŒ¹é…æ–‡ä»¶è¡Œï¼š- filenameï¼š`path` (xxx lines)
        if current_dir and current_dir.startswith('src/'):
            file_match = re.match(r'^- (.+?)ï¼š`(.+?)`\s*\((\d+) lines\)', line)
            if file_match:
                filename = file_match.group(1)
                filepath = file_match.group(2)
                lines_count = file_match.group(3)
                # ä¿ç•™åŸå§‹æ ¼å¼
                directories[current_dir].append(f"- {filename}ï¼š`{filepath}` ({lines_count} lines)")

    # åªä¿ç•™ src/ å¼€å¤´çš„ç›®å½•
    return {k: v for k, v in directories.items() if k.startswith('src/')}


def chunk_list(lst: list, chunk_size: int = 5) -> list[list]:
    """å°†åˆ—è¡¨æŒ‰æŒ‡å®šå¤§å°åˆ†å‰²ã€‚"""
    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]


def generate_analysis_requests(directories: dict[str, list[str]]) -> list[str]:
    """ç”Ÿæˆåˆ†æè¯·æ±‚å¥å­ã€‚"""
    requests = []

    for dir_path, files in directories.items():
        if not files:
            continue

        chunks = chunk_list(files, 5)

        for chunk in chunks:
            file_list = '\n'.join(chunk)
            request = f"""è¯·ä½ åˆ†æå½“å‰é¡¹ç›®ï¼š
{file_list}
è¿™äº›æ–‡ä»¶åœ¨KarisCodeæ–‡ä»¶å¤¹å†…çš„é‡å†™æ˜¯å¦1:1å¤åˆ»çš„å®Œæ•´å®ç°ï¼Œç„¶åæ›´æ–°æ–‡æ¡£docs/contrast.mdï¼Œè¯¦ç»†åˆ—å‡ºè¯­ä¹‰ä¸€è‡´çš„éƒ¨åˆ†å’Œè¯­ä¹‰ä¸ä¸€è‡´çš„éƒ¨åˆ†"""
            requests.append(request)

    return requests


def main():
    # è¯»å– project_files.md
    project_files_path = Path(__file__).parent.parent / 'docs' / 'project_files.md'

    if not project_files_path.exists():
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {project_files_path}")
        return

    content = project_files_path.read_text(encoding='utf-8')

    # è§£ææ–‡ä»¶
    directories = parse_project_files(content)

    # ç”Ÿæˆåˆ†æè¯·æ±‚
    requests = generate_analysis_requests(directories)

    # è¾“å‡ºç»“æœ
    print(f"å…±æ‰¾åˆ° {len(directories)} ä¸ª src/ ç›®å½•")
    print(f"å…±ç”Ÿæˆ {len(requests)} ä¸ªåˆ†æè¯·æ±‚\n")
    print("=" * 60)

    for i, request in enumerate(requests, 1):
        print(f"\nã€è¯·æ±‚ {i}ã€‘\n")
        print(request)
        print("\n" + "-" * 60)

    # åŒæ—¶å†™å…¥åˆ°è¾“å‡ºæ–‡ä»¶
    output_path = Path(__file__).parent.parent / 'docs' / 'analysis_requests.md'
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("# ä»£ç é‡å†™åˆ†æè¯·æ±‚\n\n")
        f.write(f"å…± {len(requests)} ä¸ªåˆ†æè¯·æ±‚\n\n")
        for i, request in enumerate(requests, 1):
            f.write(f"## è¯·æ±‚ {i}\n\n")
            f.write(f"```\n{request}\n```\n\n")

    print(f"\nç»“æœå·²ä¿å­˜åˆ°ï¼š{output_path}")


if __name__ == '__main__':
    main()
